{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRtLDWQmIl8CKarVm/el3+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Морфологические анализаторы на трансдьюсерах\n",
        "\n",
        "Мы уже видели морфологические анализаторы для разных языков (pymorphy, Mystem, spacy, stanza и др.)\n",
        "\n",
        "А делить на морфемы-то как?\n",
        "\n",
        "Хотим глоссировать!\n",
        "\n"
      ],
      "metadata": {
        "id": "boS18Ma-gLDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Если мало данных, можно использовать правила\n",
        "\n",
        "Исходить из внешнего вида слова, думать о значении морфем."
      ],
      "metadata": {
        "id": "EX-TNtN5I0NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Отступление: какие бывают языки по тому, как устроено слово?\n",
        "\n",
        "- Аналитические\n",
        "- Синтетические\n",
        " - Флективные\n",
        " - Агглютинативные\n",
        "\n",
        "Для каких проще написать правила?"
      ],
      "metadata": {
        "id": "TbvXtMs7KusB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Английский пример (потому что знаем английский)\n",
        "\n",
        "Можно вручную расписывать, \"если на конце s, а корень похож на существительное, то это существительное с показателем множественного числа, а если корень похож на глагол, это 3е лицо ед.ч.\" И так условия для каждой морфемы. Но есть некоторые готовые способы записи правил."
      ],
      "metadata": {
        "id": "6O4E2BQeJoN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Трансдьюсеры\n",
        "Например [HFST](https://github.com/apertium/lexd/blob/main/Usage.md) (Helsinki Finite-State Transducer)"
      ],
      "metadata": {
        "id": "b2iSVU_Geqco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sS https://apertium.projectjj.com/apt/install-release.sh | sudo bash\n",
        "!apt install apertium-all-dev lexd"
      ],
      "metadata": {
        "id": "QS7OQohkifQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0128f39b-8458-4e1a-9bf3-27566a643569"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning up old install, if any...\n",
            "Determining Debian/Ubuntu codename...\n",
            "Found evidence of jammy...\n",
            "Settling for jammy - enabling the Apertium release repo...\n",
            "Installing Apertium GnuPG key to /etc/apt/trusted.gpg.d/apertium.gpg\n",
            "Installing package override to /etc/apt/preferences.d/apertium.pref\n",
            "Creating /etc/apt/sources.list.d/apertium.list\n",
            "Running apt-get update...\n",
            "All done - enjoy the packages! If you just want all core tools, do: sudo apt-get install apertium-all-dev\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apertium apertium-anaphora apertium-dev apertium-eval-translator apertium-get apertium-lex-tools\n",
            "  apertium-lex-tools-dev apertium-recursive apertium-regtest apertium-separable cg3 cg3-dev gawk\n",
            "  hfst libapertium-lex-tools1 libapertium3 libcg3-1 libcg3-dev libfoma0 libfst22 libhfst-dev\n",
            "  libhfst55 libirstlm1 liblttoolbox3 libutfcpp-dev libxml2-utils libzip4 lttoolbox lttoolbox-dev\n",
            "  transfuse xsltproc\n",
            "Suggested packages:\n",
            "  gawk-doc\n",
            "The following NEW packages will be installed:\n",
            "  apertium apertium-all-dev apertium-anaphora apertium-dev apertium-eval-translator apertium-get\n",
            "  apertium-lex-tools apertium-lex-tools-dev apertium-recursive apertium-regtest apertium-separable\n",
            "  cg3 cg3-dev gawk hfst lexd libapertium-lex-tools1 libapertium3 libcg3-1 libcg3-dev libfoma0\n",
            "  libfst22 libhfst-dev libhfst55 libirstlm1 liblttoolbox3 libutfcpp-dev libxml2-utils libzip4\n",
            "  lttoolbox lttoolbox-dev transfuse xsltproc\n",
            "0 upgraded, 33 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 7,135 kB of archives.\n",
            "After this operation, 35.9 MB of additional disk space will be used.\n",
            "Get:1 http://apertium.projectjj.com/apt/release jammy/main amd64 liblttoolbox3 amd64 3.7.6-1~jammy1 [183 kB]\n",
            "Get:2 http://apertium.projectjj.com/apt/release jammy/main amd64 libapertium3 amd64 3.9.4-1~jammy1 [339 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gawk amd64 1:5.1.0-1ubuntu0.1 [447 kB]\n",
            "Get:4 http://apertium.projectjj.com/apt/release jammy/main amd64 lttoolbox amd64 3.7.6-1~jammy1 [24.1 kB]\n",
            "Get:5 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium amd64 3.9.4-1~jammy1 [329 kB]\n",
            "Get:6 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-anaphora amd64 1.1.1-3~jammy1 [39.1 kB]\n",
            "Get:7 http://apertium.projectjj.com/apt/release jammy/main amd64 lttoolbox-dev amd64 3.7.6-1~jammy1 [95.9 kB]\n",
            "Get:8 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-dev amd64 3.9.4-1~jammy1 [91.6 kB]\n",
            "Get:9 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-eval-translator all 1.2.1-2~jammy1 [5,660 B]\n",
            "Get:10 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-get all 1.0.0-2~sid1 [7,560 B]\n",
            "Get:11 http://apertium.projectjj.com/apt/release jammy/main amd64 libapertium-lex-tools1 amd64 0.4.2-3~jammy1 [69.1 kB]\n",
            "Get:12 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-lex-tools amd64 0.4.2-3~jammy1 [45.4 kB]\n",
            "Get:13 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-lex-tools-dev amd64 0.4.2-3~jammy1 [21.2 kB]\n",
            "Get:14 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-recursive amd64 1.1.2-3~jammy1 [179 kB]\n",
            "Get:15 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-regtest all 0.9.1-2~sid1 [89.6 kB]\n",
            "Get:16 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-separable amd64 0.6.1-3~jammy1 [28.0 kB]\n",
            "Get:17 http://apertium.projectjj.com/apt/release jammy/main amd64 libcg3-1 amd64 1.4.6-1~jammy1 [306 kB]\n",
            "Get:18 http://apertium.projectjj.com/apt/release jammy/main amd64 cg3 amd64 1.4.6-1~jammy1 [139 kB]\n",
            "Get:19 http://apertium.projectjj.com/apt/release jammy/main amd64 libcg3-dev amd64 1.4.6-1~jammy1 [5,160 B]\n",
            "Get:20 http://apertium.projectjj.com/apt/release jammy/main amd64 cg3-dev all 1.4.6-1~jammy1 [3,052 B]\n",
            "Get:21 http://apertium.projectjj.com/apt/release jammy/main amd64 libfoma0 amd64 0.10.0-4~jammy1 [101 kB]\n",
            "Get:22 http://apertium.projectjj.com/apt/release jammy/main amd64 libfst22 amd64 1.7.9-3~jammy1 [1,986 kB]\n",
            "Get:23 http://apertium.projectjj.com/apt/release jammy/main amd64 libhfst55 amd64 3.16.0-4~jammy1 [1,509 kB]\n",
            "Get:24 http://apertium.projectjj.com/apt/release jammy/main amd64 hfst amd64 3.16.0-4~jammy1 [497 kB]\n",
            "Get:25 http://apertium.projectjj.com/apt/release jammy/main amd64 lexd amd64 1.3.1-2~jammy1 [82.6 kB]\n",
            "Get:26 http://apertium.projectjj.com/apt/release jammy/main amd64 libhfst-dev amd64 3.16.0-4~jammy1 [118 kB]\n",
            "Get:27 http://apertium.projectjj.com/apt/release jammy/main amd64 transfuse amd64 0.5.8-4~jammy1 [79.4 kB]\n",
            "Get:28 http://apertium.projectjj.com/apt/release jammy/main amd64 apertium-all-dev all 3.8.1-6~jammy1 [2,280 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxml2-utils amd64 2.9.13+dfsg-1ubuntu0.3 [40.2 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xsltproc amd64 1.1.34-4ubuntu0.22.04.1 [14.7 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libutfcpp-dev amd64 3.2.1-2 [10.2 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libirstlm1 amd64 6.00.05-3 [190 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzip4 amd64 1.7.3-1ubuntu2 [55.0 kB]\n",
            "Fetched 7,135 kB in 1s (7,209 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package gawk.\n",
            "(Reading database ... 121658 files and directories currently installed.)\n",
            "Preparing to unpack .../00-gawk_1%3a5.1.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gawk (1:5.1.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package liblttoolbox3:amd64.\n",
            "Preparing to unpack .../01-liblttoolbox3_3.7.6-1~jammy1_amd64.deb ...\n",
            "Unpacking liblttoolbox3:amd64 (3.7.6-1~jammy1) ...\n",
            "Selecting previously unselected package libapertium3:amd64.\n",
            "Preparing to unpack .../02-libapertium3_3.9.4-1~jammy1_amd64.deb ...\n",
            "Unpacking libapertium3:amd64 (3.9.4-1~jammy1) ...\n",
            "Selecting previously unselected package libxml2-utils.\n",
            "Preparing to unpack .../03-libxml2-utils_2.9.13+dfsg-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libxml2-utils (2.9.13+dfsg-1ubuntu0.3) ...\n",
            "Selecting previously unselected package lttoolbox.\n",
            "Preparing to unpack .../04-lttoolbox_3.7.6-1~jammy1_amd64.deb ...\n",
            "Unpacking lttoolbox (3.7.6-1~jammy1) ...\n",
            "Selecting previously unselected package xsltproc.\n",
            "Preparing to unpack .../05-xsltproc_1.1.34-4ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking xsltproc (1.1.34-4ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package apertium.\n",
            "Preparing to unpack .../06-apertium_3.9.4-1~jammy1_amd64.deb ...\n",
            "Unpacking apertium (3.9.4-1~jammy1) ...\n",
            "Selecting previously unselected package apertium-anaphora.\n",
            "Preparing to unpack .../07-apertium-anaphora_1.1.1-3~jammy1_amd64.deb ...\n",
            "Unpacking apertium-anaphora (1.1.1-3~jammy1) ...\n",
            "Selecting previously unselected package libutfcpp-dev:amd64.\n",
            "Preparing to unpack .../08-libutfcpp-dev_3.2.1-2_amd64.deb ...\n",
            "Unpacking libutfcpp-dev:amd64 (3.2.1-2) ...\n",
            "Selecting previously unselected package lttoolbox-dev.\n",
            "Preparing to unpack .../09-lttoolbox-dev_3.7.6-1~jammy1_amd64.deb ...\n",
            "Unpacking lttoolbox-dev (3.7.6-1~jammy1) ...\n",
            "Selecting previously unselected package apertium-dev.\n",
            "Preparing to unpack .../10-apertium-dev_3.9.4-1~jammy1_amd64.deb ...\n",
            "Unpacking apertium-dev (3.9.4-1~jammy1) ...\n",
            "Selecting previously unselected package apertium-eval-translator.\n",
            "Preparing to unpack .../11-apertium-eval-translator_1.2.1-2~jammy1_all.deb ...\n",
            "Unpacking apertium-eval-translator (1.2.1-2~jammy1) ...\n",
            "Selecting previously unselected package apertium-get.\n",
            "Preparing to unpack .../12-apertium-get_1.0.0-2~sid1_all.deb ...\n",
            "Unpacking apertium-get (1.0.0-2~sid1) ...\n",
            "Selecting previously unselected package libapertium-lex-tools1:amd64.\n",
            "Preparing to unpack .../13-libapertium-lex-tools1_0.4.2-3~jammy1_amd64.deb ...\n",
            "Unpacking libapertium-lex-tools1:amd64 (0.4.2-3~jammy1) ...\n",
            "Selecting previously unselected package libirstlm1:amd64.\n",
            "Preparing to unpack .../14-libirstlm1_6.00.05-3_amd64.deb ...\n",
            "Unpacking libirstlm1:amd64 (6.00.05-3) ...\n",
            "Selecting previously unselected package apertium-lex-tools.\n",
            "Preparing to unpack .../15-apertium-lex-tools_0.4.2-3~jammy1_amd64.deb ...\n",
            "Unpacking apertium-lex-tools (0.4.2-3~jammy1) ...\n",
            "Selecting previously unselected package apertium-lex-tools-dev.\n",
            "Preparing to unpack .../16-apertium-lex-tools-dev_0.4.2-3~jammy1_amd64.deb ...\n",
            "Unpacking apertium-lex-tools-dev (0.4.2-3~jammy1) ...\n",
            "Selecting previously unselected package apertium-recursive.\n",
            "Preparing to unpack .../17-apertium-recursive_1.1.2-3~jammy1_amd64.deb ...\n",
            "Unpacking apertium-recursive (1.1.2-3~jammy1) ...\n",
            "Selecting previously unselected package apertium-regtest.\n",
            "Preparing to unpack .../18-apertium-regtest_0.9.1-2~sid1_all.deb ...\n",
            "Unpacking apertium-regtest (0.9.1-2~sid1) ...\n",
            "Selecting previously unselected package apertium-separable.\n",
            "Preparing to unpack .../19-apertium-separable_0.6.1-3~jammy1_amd64.deb ...\n",
            "Unpacking apertium-separable (0.6.1-3~jammy1) ...\n",
            "Selecting previously unselected package libcg3-1:amd64.\n",
            "Preparing to unpack .../20-libcg3-1_1.4.6-1~jammy1_amd64.deb ...\n",
            "Unpacking libcg3-1:amd64 (1.4.6-1~jammy1) ...\n",
            "Selecting previously unselected package cg3.\n",
            "Preparing to unpack .../21-cg3_1.4.6-1~jammy1_amd64.deb ...\n",
            "Unpacking cg3 (1.4.6-1~jammy1) ...\n",
            "Selecting previously unselected package libcg3-dev:amd64.\n",
            "Preparing to unpack .../22-libcg3-dev_1.4.6-1~jammy1_amd64.deb ...\n",
            "Unpacking libcg3-dev:amd64 (1.4.6-1~jammy1) ...\n",
            "Selecting previously unselected package cg3-dev.\n",
            "Preparing to unpack .../23-cg3-dev_1.4.6-1~jammy1_all.deb ...\n",
            "Unpacking cg3-dev (1.4.6-1~jammy1) ...\n",
            "Selecting previously unselected package libfoma0:amd64.\n",
            "Preparing to unpack .../24-libfoma0_0.10.0-4~jammy1_amd64.deb ...\n",
            "Unpacking libfoma0:amd64 (0.10.0-4~jammy1) ...\n",
            "Selecting previously unselected package libfst22.\n",
            "Preparing to unpack .../25-libfst22_1.7.9-3~jammy1_amd64.deb ...\n",
            "Unpacking libfst22 (1.7.9-3~jammy1) ...\n",
            "Selecting previously unselected package libhfst55.\n",
            "Preparing to unpack .../26-libhfst55_3.16.0-4~jammy1_amd64.deb ...\n",
            "Unpacking libhfst55 (3.16.0-4~jammy1) ...\n",
            "Selecting previously unselected package hfst.\n",
            "Preparing to unpack .../27-hfst_3.16.0-4~jammy1_amd64.deb ...\n",
            "Unpacking hfst (3.16.0-4~jammy1) ...\n",
            "Selecting previously unselected package lexd.\n",
            "Preparing to unpack .../28-lexd_1.3.1-2~jammy1_amd64.deb ...\n",
            "Unpacking lexd (1.3.1-2~jammy1) ...\n",
            "Selecting previously unselected package libhfst-dev.\n",
            "Preparing to unpack .../29-libhfst-dev_3.16.0-4~jammy1_amd64.deb ...\n",
            "Unpacking libhfst-dev (3.16.0-4~jammy1) ...\n",
            "Selecting previously unselected package libzip4:amd64.\n",
            "Preparing to unpack .../30-libzip4_1.7.3-1ubuntu2_amd64.deb ...\n",
            "Unpacking libzip4:amd64 (1.7.3-1ubuntu2) ...\n",
            "Selecting previously unselected package transfuse.\n",
            "Preparing to unpack .../31-transfuse_0.5.8-4~jammy1_amd64.deb ...\n",
            "Unpacking transfuse (0.5.8-4~jammy1) ...\n",
            "Selecting previously unselected package apertium-all-dev.\n",
            "Preparing to unpack .../32-apertium-all-dev_3.8.1-6~jammy1_all.deb ...\n",
            "Unpacking apertium-all-dev (3.8.1-6~jammy1) ...\n",
            "Setting up gawk (1:5.1.0-1ubuntu0.1) ...\n",
            "Setting up libzip4:amd64 (1.7.3-1ubuntu2) ...\n",
            "Setting up xsltproc (1.1.34-4ubuntu0.22.04.1) ...\n",
            "Setting up libcg3-1:amd64 (1.4.6-1~jammy1) ...\n",
            "Setting up libfoma0:amd64 (0.10.0-4~jammy1) ...\n",
            "Setting up libirstlm1:amd64 (6.00.05-3) ...\n",
            "Setting up libutfcpp-dev:amd64 (3.2.1-2) ...\n",
            "Setting up liblttoolbox3:amd64 (3.7.6-1~jammy1) ...\n",
            "Setting up libfst22 (1.7.9-3~jammy1) ...\n",
            "Setting up cg3 (1.4.6-1~jammy1) ...\n",
            "Setting up apertium-eval-translator (1.2.1-2~jammy1) ...\n",
            "Setting up libxml2-utils (2.9.13+dfsg-1ubuntu0.3) ...\n",
            "Setting up libhfst55 (3.16.0-4~jammy1) ...\n",
            "Setting up lttoolbox (3.7.6-1~jammy1) ...\n",
            "Setting up apertium-regtest (0.9.1-2~sid1) ...\n",
            "Setting up transfuse (0.5.8-4~jammy1) ...\n",
            "Setting up libapertium-lex-tools1:amd64 (0.4.2-3~jammy1) ...\n",
            "Setting up apertium-lex-tools (0.4.2-3~jammy1) ...\n",
            "Setting up lttoolbox-dev (3.7.6-1~jammy1) ...\n",
            "Setting up libcg3-dev:amd64 (1.4.6-1~jammy1) ...\n",
            "Setting up lexd (1.3.1-2~jammy1) ...\n",
            "Setting up libapertium3:amd64 (3.9.4-1~jammy1) ...\n",
            "Setting up apertium-lex-tools-dev (0.4.2-3~jammy1) ...\n",
            "Setting up apertium-separable (0.6.1-3~jammy1) ...\n",
            "Setting up apertium-anaphora (1.1.1-3~jammy1) ...\n",
            "Setting up hfst (3.16.0-4~jammy1) ...\n",
            "Setting up libhfst-dev (3.16.0-4~jammy1) ...\n",
            "Setting up cg3-dev (1.4.6-1~jammy1) ...\n",
            "Setting up apertium (3.9.4-1~jammy1) ...\n",
            "Setting up apertium-recursive (1.1.2-3~jammy1) ...\n",
            "Setting up apertium-dev (3.9.4-1~jammy1) ...\n",
            "Setting up apertium-get (1.0.0-2~sid1) ...\n",
            "Setting up apertium-all-dev (3.8.1-6~jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это не питон, что это за язык? То, что после восклицательного знака - команды Linux (линуксовские), команды, которые работают в терминале"
      ],
      "metadata": {
        "id": "54BsbcD05V8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.lexd\n",
        "PATTERNS\n",
        "VerbRoot VerbInfl\n",
        "\n",
        "LEXICON VerbRoot\n",
        "sing\n",
        "walk\n",
        "\n",
        "LEXICON VerbInfl\n",
        "<v><pres>:\n",
        "<v><pres><p3><sg>:s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts066_jn0Ysd",
        "outputId": "bd637f17-784f-4026-9f7a-2b3412dceff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing eng.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lexd eng.lexd > eng.generator.att\n",
        "!lt-comp rl eng.generator.att eng.analyser.bin\n",
        "! echo 'sings' | lt-proc eng.analyser.bin  # даёт разбор слова"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eSkZr3a0YeM",
        "outputId": "5ab1230e-5d1c-44a0-a694-5afc2a2fa2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 13 14\n",
            "^sings/sing<v><pres><p3><sg>$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "- Где деление на морфемы?\n",
        "- Будет.\n",
        "```"
      ],
      "metadata": {
        "id": "kq2J6r8q4aec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы поняли логику, научитесь разбирать ещё слова cat, cats, dog, dogs."
      ],
      "metadata": {
        "id": "yZ2MKjqteDL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.lexd\n",
        "PATTERNS\n",
        "VerbRoot VerbInfl\n",
        "NounRoot NounInfl\n",
        "\n",
        "LEXICON VerbRoot\n",
        "sing\n",
        "walk\n",
        "dance\n",
        "\n",
        "LEXICON VerbInfl\n",
        "<v><pres>:\n",
        "<v><pres><p3><sg>:s\n",
        "\n",
        "LEXICON NounRoot\n",
        "cat\n",
        "dog\n",
        "\n",
        "LEXICON NounInfl\n",
        "<n><sg>:\n",
        "<n><pl>:s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM-I-FiB0Cej",
        "outputId": "bd480f82-f479-497e-e5d7-f68506eaab04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eng.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# пересобираем генератор и анализатор\n",
        "!lexd eng.lexd > eng.generator.att\n",
        "!lt-comp rl eng.generator.att eng.analyser.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgOgZPnV0HZK",
        "outputId": "73321386-ec90-4d13-835d-9c7dc41b5e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 22 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo 'dogs' | lt-proc eng.analyser.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKxtxJUJIYhE",
        "outputId": "441e00c2-dcdc-48fa-a394-7b5f80ee10fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^dogs/dog<n><pl>$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! lexd eng.lexd | hfst-txt2fst -o eng.generator.hfst\n",
        "! hfst-fst2strings eng.generator.hfst  # генерирует все возможные формы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSFZeQWN14uz",
        "outputId": "2d7f4976-ac88-4bf3-a252-3a446471eeb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sing<v><pres>:sing\n",
            "sing<v><pres><p3><sg>:sings\n",
            "walk<v><pres>:walk\n",
            "walk<v><pres><p3><sg>:walks\n",
            "dance<v><pres>:dance\n",
            "dance<v><pres><p3><sg>:dances\n",
            "dog<n><sg>:dog\n",
            "dog<n><pl>:dogs\n",
            "cat<n><sg>:cat\n",
            "cat<n><pl>:cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### А что происходит, что такое Finite-State Transducer?\n",
        "\n",
        "Finite-State Transducer - конечный преобразовывающий автомат\n",
        "\n",
        "Понятнее? :)\n",
        "\n",
        "Автомат - математическая модель, они бывают разные, поэтому давайте сразу про конечные автоматы\n",
        "\n",
        "\n",
        "Конечный атомат состоит из:\n",
        "- \"алфавита\" состояний\n",
        "- входного алфавита\n",
        "- переходов между состояниями\n",
        "- нального состояния\n",
        "- конечных состояний\n",
        "\n",
        "Можно представить в виде\n",
        "- графа\n",
        "- матрицы\n",
        "- БНФ (Бэкусовская нормальная форма или Бэкуса-Науэра форма)\n",
        "\n",
        "![картинка тут](https://raw.githubusercontent.com/tbkazakova/drafts/main/auto.png)\n",
        "\n",
        "ε – пустой символ"
      ],
      "metadata": {
        "id": "lu5r7Gqlec1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бывают автоматы\n",
        "- распознающие — определяют соответствие входной цепочки конечному автомату\n",
        "- преобразующие — производят определенные действия по входной цепочке\n",
        "\n",
        "Наш автомат преобразующий: он ходит по слову и по частям заменяет слово на <морфологические теги>\n"
      ],
      "metadata": {
        "id": "IcevdkXAyvlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подвид КА (конечных автоматов):\n",
        "- стохастический КА — каждому переходу приписана его вероятность\n",
        "\n",
        "(в lexd можно это прописать, ведь есть более вероятные разборы и менее)"
      ],
      "metadata": {
        "id": "sIQQSGTN3rdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возвращаемся к HFST\n",
        "На самом деле в HFST две больших части, два формализма [lexd](https://github.com/apertium/lexd/blob/main/Usage.md) и twolc (two-level compiler).\n",
        "\n",
        "twolc нужен для морфонологии. Порой одна глубинная форма реализуется по-разному. (примеры из русского?)\n",
        "\n",
        "Как это записать, если не хочется указывать в лексиконе алломорфы разными сущностями?\n",
        "\n",
        "Вот для этого и нужен twolc. two-level compiler: на первом уровне даём \"глубинные формы\", на втором расписываем их поверхностные реализации.\n"
      ],
      "metadata": {
        "id": "bz0Y8Zda4LTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Английский (правила для s во множественном числе)\n",
        "\n",
        "Иногда показатель PL выглядит как *-es*, а не *-s*. В каких случаях?\n",
        "\n",
        "Как вы думаете, какая глубинная форма у этого показателя? Почему?"
      ],
      "metadata": {
        "id": "sDPfLhgaPbH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.lexd\n",
        "PATTERNS\n",
        "NounRoot NounInfl\n",
        "\n",
        "LEXICON NounRoot\n",
        "dog\n",
        "cat\n",
        "bus\n",
        "fox\n",
        "watch\n",
        "wish\n",
        "fez\n",
        "\n",
        "LEXICON NounInfl\n",
        "<n><sg>:\n",
        "<n><pl>:{S}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyuTzHiDOjI0",
        "outputId": "f76a44b2-f5ee-4bd5-cfcc-dff92d593a52"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eng.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lexd eng.lexd > eng.generator.att\n",
        "!lt-comp rl eng.generator.att eng.analyser.bin\n",
        "! echo 'dogs' | lt-proc eng.analyser.bin\n",
        "! echo 'dog\\{S\\}' | lt-proc eng.analyser.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtLABWQAOi35",
        "outputId": "4c9816d3-d2cb-4251-93d4-1ddf51083bba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 21 27\n",
            "^dogs/*dogs$\n",
            "^dog\\{S\\}/dog<n><pl>$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! lexd eng.lexd | hfst-txt2fst -o eng.generator.hfst\n",
        "! hfst-invert eng.generator.hfst -o eng.analyzer.hfst"
      ],
      "metadata": {
        "id": "wVZIPUfDOivB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.twol\n",
        "Alphabet\n",
        "  a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
        "  %{S%}:es %{S%}:s\n",
        ";\n",
        "Rules\n",
        "\"{S} s _ realisation\"\n",
        "%{S%}:es <=> s|x|z|(ch)|(sh) _ ;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqLRJoiCOiZ_",
        "outputId": "84303e7c-45d8-4ec5-dfe8-3dadd8507122"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eng.twol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! hfst-twolc eng.twol -o eng.twol.hfst\n",
        "! lexd eng.lexd | hfst-txt2fst -o eng.lexd.hfst\n",
        "#! hfst-fst2strings eng.lexd.hfst\n",
        "! hfst-compose-intersect eng.lexd.hfst eng.twol.hfst -o eng.generator.hfst\n",
        "#! hfst-fst2strings eng.generator.hfst\n",
        "! hfst-invert eng.generator.hfst -o eng.analyzer.hfst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WszS-OjgPZBZ",
        "outputId": "0fcfa17a-ecb1-4f2b-f8c3-4d681089bd7f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading input from eng.twol.\n",
            "Writing output to eng.twol.hfst.\n",
            "Reading alphabet.\n",
            "Reading rules and compiling their contexts and centers.\n",
            "Compiling rules.\n",
            "Storing rules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ! echo \"dogs\" | hfst-lookup eng.analyzer.hfst\n",
        "a[2].split()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_AAyX0htQRUk",
        "outputId": "bdcade03-2511-4216-ee73-0c543f5bba7f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dogs+?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ! echo \"foxes\" | hfst-lookup eng.analyzer.hfst\n",
        "a[2].split()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h7aZ3zFlEJyN",
        "outputId": "b9aee67f-dabf-4de2-d0bd-ebb3dae24833"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fox<n><pl>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ! echo \"buses\" | hfst-lookup eng.analyzer.hfst\n",
        "a[2].split()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9KdR6z_tQlID",
        "outputId": "d46294ee-6c58-4381-f701-36ce6f8f525c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bus<n><pl>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# а неправильные слова не разбирает\n",
        "a = ! echo \"doges\" | hfst-lookup eng.analyzer.hfst\n",
        "a[2].split()[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D0wRhhbMQp72",
        "outputId": "390bae41-46ac-4cec-d1fe-c182662723fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'doges+?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! hfst-fst2strings eng.generator.hfst  # генерирует все возможные формы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "relpr6LqEShi",
        "outputId": "be91b297-5190-4c3d-95e2-d869ef71fdbb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bus<n><sg>:bus\n",
            "bus<n><pl>:buses\n",
            "cat<n><sg>:cat\n",
            "cat<n><pl>:cates\n",
            "dog<n><sg>:dog\n",
            "dog<n><pl>:doges\n",
            "fez<n><sg>:fez\n",
            "fez<n><pl>:fezes\n",
            "fox<n><sg>:fox\n",
            "fox<n><pl>:foxes\n",
            "watch<n><sg>:watch\n",
            "watch<n><pl>:watches\n",
            "wish<n><sg>:wish\n",
            "wish<n><pl>:wishes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можете добавить остальные случаи, когда \"es\"."
      ],
      "metadata": {
        "id": "Je_nPy6GQ3ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Как сделать сегментацию?"
      ],
      "metadata": {
        "id": "2h4vWRNBQyRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.lexd\n",
        "PATTERNS\n",
        "NounRoot NounInfl\n",
        "\n",
        "LEXICON NounRoot\n",
        "dog\n",
        "cat\n",
        "bus\n",
        "\n",
        "LEXICON NounInfl\n",
        "<n><sg>:\n",
        "<n><pl>:>{S}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Unv8qLmQxJm",
        "outputId": "16ddec05-25d7-4ff0-c6fe-aed724654aa7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eng.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.twol\n",
        "Alphabet\n",
        "  a b c d e f g h i j k l m n o p q r s t u v w x y z\n",
        "  %{S%}:es %{S%}:s\n",
        "  %>:0\n",
        ";\n",
        "Rules\n",
        "\"{S} s _ realisation\"\n",
        "%{S%}:es <=> s %>: _ ;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_6GV9cmSP_c",
        "outputId": "75b1a33c-ec6d-432d-efdd-75d776e55510"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eng.twol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lexd eng.lexd > eng.generator.att\n",
        "!lt-comp rl eng.generator.att eng.analyser.bin\n",
        "! hfst-twolc eng.twol -o eng.twol.hfst\n",
        "! lexd eng.lexd | hfst-txt2fst -o eng.lexd.hfst\n",
        "#! hfst-fst2strings eng.lexd.hfst\n",
        "! hfst-compose-intersect eng.lexd.hfst eng.twol.hfst -o eng.generator.hfst\n",
        "#! hfst-fst2strings eng.generator.hfst\n",
        "! hfst-invert eng.generator.hfst -o eng.analyzer.hfst"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF7EMsUCSPr_",
        "outputId": "d1a2816c-481a-4511-de67-24ab1af1dc70"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 13 15\n",
            "Reading input from eng.twol.\n",
            "Writing output to eng.twol.hfst.\n",
            "Reading alphabet.\n",
            "Reading rules and compiling their contexts and centers.\n",
            "Compiling rules.\n",
            "Storing rules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! hfst-fst2strings eng.generator.hfst  # генерирует все возможные формы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ei1gtCrX3Fm",
        "outputId": "217467a6-9504-4b1c-bef1-7952617e4f4c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bus<n><sg>:bus\n",
            "bus<n><pl>:buses\n",
            "cat<n><sg>:cat\n",
            "cat<n><pl>:cats\n",
            "dog<n><sg>:dog\n",
            "dog<n><pl>:dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!hfst-invert eng.lexd.hfst -o eng.inv_seg.hfst\n",
        "!hfst-compose-intersect -1 eng.lexd.hfst -2 eng.twol.hfst | hfst-minimise -o eng-seg.hfst\n",
        "!hfst-compose -1 eng.inv_seg.hfst -2 eng-seg.hfst -o eng.seg.hfst\n",
        "!hfst-minimise eng.seg.hfst | hfst-invert | hfst-fst2fst -O -o eng.segmenter.hfst"
      ],
      "metadata": {
        "id": "a0XJzPThZAtD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! hfst-fst2strings eng.segmenter.hfst  # генерирует все возможные формы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXwTt2rrZ-Wy",
        "outputId": "9d1d491d-b514-4e0b-de52-09c8e6d437c4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bus\n",
            "buses:bus>{S}\n",
            "cat\n",
            "cats:cat>{S}\n",
            "dog\n",
            "dogs:dog>{S}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer_seg = ! echo 'buses' | hfst-lookup eng.segmenter.hfst\n",
        "answer_gl = ! echo 'buses' | hfst-lookup eng.analyzer.hfst\n",
        "\n",
        "parts = answer_seg[0].split()[2].replace('>', '-')\n",
        "gloss = answer_gl[2].split()[2].replace('<n>', '').replace('<', '-').replace('>', '')\n",
        "\n",
        "parts, gloss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1zoyq6TaXMu",
        "outputId": "d6894936-b558-48d4-c720-5cd47406ca4c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bus-{S}', 'bus-pl')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно ли получить *bus-es*, а не *bus-{S}*?\n",
        "\n",
        "Можно ли разбирать слова с неизвестным корнем?\n",
        "\n",
        "Можно ли добавить ранжирование вариантов разбора по вероятности?\n",
        "\n",
        "- Можно, но я ещё не научилась.\n"
      ],
      "metadata": {
        "id": "7V_gv63Paaaj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Где взять уже готовые анализаторы?\n",
        "- Посмотреть репозитории проекта [apertium](https://github.com/apertium). Есть [онлайн версии](https://beta.apertium.org/index.eng.html#analysis?aLang=sah&aQ=%D0%91%D1%83%20%D1%81%D0%B0%D1%85%D0%B0%D0%BB%D1%8B%D1%8B%20%D0%BC%D0%BE%D1%80%D1%84%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D0%B9%20%D1%8B%D1%80%D1%8B%D1%82%D1%8B%D1%8B.), чтобы попробовать.\n"
      ],
      "metadata": {
        "id": "RosoJ-VhcJP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Эвенский (глаголы)\n",
        "\n",
        "Вот [список глосс эвенской экспедиции](https://www.evenlang.ru/evenlang_online/static/files/eve_glosses_draft_20220115_official.pdf)\n",
        "\n",
        "Научимся разбирать *ur-ri-wu* (уйти-pst-1sg) и *em-ni-wu* (прийти-pst-1sg). r перед n всегда ассимилируется.\n",
        "\n",
        "Добавьте правила для *it-ti-wu* (увидеть-pst-1sg), *das̆-s̆i-wu* (укрыть-pst-1sg). Посмотрите на таблицу глосс и добавьте оставшиеся варианты реализации <pst>.\n",
        "\n",
        "Добавим необязательный слот для аспекта перед показателем времени.\n",
        "\n",
        "Попробуйте добавить парадигму непрошедшего времени."
      ],
      "metadata": {
        "id": "YZEpCmyHc179"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eve.lexd\n",
        "PATTERNS\n",
        "VerbStem [<v>:] VerbTencePNum\n",
        "\n",
        "LEXICON VerbStem\n",
        "<уйти>:ur\n",
        "<прийти>:em\n",
        "\n",
        "PATTERN VerbTencePNum\n",
        "Verbpst VerbPNumpst\n",
        "\n",
        "LEXICON Verbpst\n",
        "<pst>:{R}i\n",
        "\n",
        "LEXICON VerbPNumpst\n",
        "<p1><sg>:wu\n",
        "<p1><sg>:w\n",
        "<p2><sg>:š\n",
        "<p3><sg>:n\n",
        "<p1><pl><inc>:t\n",
        "<p1><pl><exc>:wun\n",
        "<p2><pl>:šan\n",
        "<p3><pl>:tan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxWMQoolytwz",
        "outputId": "43ff3088-d760-4373-d49b-61869f0232ec"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eve.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lexd eve.lexd > eve.generator.att\n",
        "!lt-comp rl eve.generator.att eve.analyser.bin\n",
        "! echo 'urrin' | lt-proc eve.analyser.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Asqnb3z2psl",
        "outputId": "d281f183-3f80-45e1-d7b4-d6890f7da991"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 18 25\n",
            "^urrin/*urrin$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! lexd eve.lexd | hfst-txt2fst -o eve.generator.hfst\n",
        "! hfst-invert eve.generator.hfst -o eve.analyzer.hfst"
      ],
      "metadata": {
        "id": "X0ZK3pl11xdF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eve.twol\n",
        "Alphabet\n",
        "  a b c d e f g i j k l m n o p r s t u v w x z ŋ č ž š ə ɨ ɵ γ\n",
        "  %{R%}:n %{R%}:r\n",
        ";\n",
        "Rules\n",
        "\"{R} m _ realisation\"\n",
        "%{R%}:n <=> m _ ;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUsfDPxr16ij",
        "outputId": "14b4add8-f4ac-4593-abfd-416c2ac782da"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eve.twol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! hfst-twolc eve.twol -o eve.twol.hfst\n",
        "! lexd eve.lexd | hfst-txt2fst -o eve.lexd.hfst\n",
        "#! hfst-fst2strings eve.lexd.hfst\n",
        "! hfst-compose-intersect eve.lexd.hfst eve.twol.hfst -o eve.generator.hfst\n",
        "#! hfst-fst2strings eve.generator.hfst\n",
        "! hfst-invert eve.generator.hfst -o eve.analyzer.hfst"
      ],
      "metadata": {
        "id": "i9TC1UVn1ag5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbccdd01-2963-4710-d176-af2b9bdc7aed"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading input from eve.twol.\n",
            "Writing output to eve.twol.hfst.\n",
            "Reading alphabet.\n",
            "Reading rules and compiling their contexts and centers.\n",
            "Compiling rules.\n",
            "Storing rules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"urrin\" | hfst-lookup eve.analyzer.hfst"
      ],
      "metadata": {
        "id": "n8ya1Q0K0T5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727d9b3b-a784-4979-87f5-d51f2d5896fb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hfst-lookup: warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\n",
            "Using HFST basic transducer format and performing slow lookups\n",
            "> urrin\t<уйти><v><pst><p3><sg>\t0.000000\n",
            "\n",
            "> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ! echo \"emnin\" | hfst-lookup eve.analyzer.hfst\n",
        "a[2].split()[2]"
      ],
      "metadata": {
        "id": "YVWmb0rEQUx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d45cbdc1-542c-4f3d-b7dc-cdc58a4f6067"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<прийти><v><pst><p3><sg>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Готовое"
      ],
      "metadata": {
        "id": "ghOnp34eGxOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Попробуем библиотеку polyglot на основе morfessor (это не трансдьюсеры, это другое)"
      ],
      "metadata": {
        "id": "cJNw6Vig_HQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install polyglot"
      ],
      "metadata": {
        "id": "3DuJG-dN_CN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e02487-48fd-438e-f6e3-09e6da121dab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/126.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/126.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52558 sha256=69479e0acded4febad189047d7500d629237fced16138ec37682e7eecf9de60e\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/92/4a/b172589446ba537db3bdb9a1f2204f27fe71217981c14ac368\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install icu"
      ],
      "metadata": {
        "id": "NGGNg19j_PPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989e4329-3cfb-4933-bd90-e0e55695c123"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icu\n",
            "  Downloading icu-0.0.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: icu\n",
            "Successfully installed icu-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyicu"
      ],
      "metadata": {
        "id": "xN9rvJGq_h7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37480812-39bd-467d-a22e-12d5df959541"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyicu\n",
            "  Downloading PyICU-2.12.tar.gz (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.0/260.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.12-cp310-cp310-linux_x86_64.whl size=1754544 sha256=c2f97a02a83d2033875fcbe535302318da97aeb5a48a5f62f6000319ebf63060\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/60/95/66d97ac2fdc8be8e526c4254047405fe77feaf064282d1ad07\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pycld2"
      ],
      "metadata": {
        "id": "RN33EDp3_vtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7947bef-2dac-4608-9360-5522833c2f6a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9904038 sha256=e2b5d159d5ae354e95d2997b887113caa3fef0fd01fe2bfd57f20aa6958397fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install morfessor"
      ],
      "metadata": {
        "id": "vL_4QhclB7RU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42ef7ab-5871-4db1-8385-dea8f43a0482"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from polyglot.downloader import downloader\n",
        "print(downloader.supported_languages_table(\"morph2\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eYfVc1R-_pK",
        "outputId": "b72d4627-1be3-4733-ec67-e27785c465b8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1. Kapampangan                2. Italian                    3. Upper Sorbian            \n",
            "  4. Sakha                      5. Hindi                      6. French                   \n",
            "  7. Spanish; Castilian         8. Vietnamese                 9. Arabic                   \n",
            " 10. Macedonian                11. Pashto, Pushto            12. Bosnian-Croatian-Serbian \n",
            " 13. Egyptian Arabic           14. Norwegian Nynorsk         15. Sundanese                \n",
            " 16. Sicilian                  17. Azerbaijani               18. Bulgarian                \n",
            " 19. Yoruba                    20. Tajik                     21. Georgian                 \n",
            " 22. Tatar                     23. Galician                  24. Malagasy                 \n",
            " 25. Uighur, Uyghur            26. Amharic                   27. Venetian                 \n",
            " 28. Yiddish                   29. Norwegian                 30. Alemannic                \n",
            " 31. Estonian                  32. West Flemish              33. Divehi; Dhivehi; Mald... \n",
            " 34. Japanese                  35. Ilokano                   36. Haitian; Haitian Creole  \n",
            " 37. Belarusian                38. Greek, Modern             39. Ossetian, Ossetic        \n",
            " 40. Welsh                     41. Malayalam                 42. Albanian                 \n",
            " 43. Marathi (Marāṭhī)         44. Armenian                  45. Slovene                  \n",
            " 46. Korean                    47. Breton                    48. Irish                    \n",
            " 49. Luxembourgish, Letzeb...  50. Bengali                   51. Serbian                  \n",
            " 52. Fiji Hindi                53. Javanese                  54. Finnish                  \n",
            " 55. Gan Chinese               56. Kirghiz, Kyrgyz           57. Catalan; Valencian       \n",
            " 58. Quechua                   59. Croatian                  60. Dutch                    \n",
            " 61. Swedish                   62. Ido                       63. Tagalog                  \n",
            " 64. Sanskrit (Saṁskṛta)       65. Piedmontese language      66. Asturian                 \n",
            " 67. Danish                    68. Cebuano                   69. Western Frisian          \n",
            " 70. Kannada                   71. Scots                     72. Maltese                  \n",
            " 73. Swahili                   74. Limburgish, Limburgan...  75. Waray-Waray              \n",
            " 76. Lombard language          77. Uzbek                     78. Kurdish                  \n",
            " 79. Latvian                   80. Burmese                   81. Aragonese                \n",
            " 82. Volapük                   83. Northern Sami             84. Faroese                  \n",
            " 85. Kazakh                    86. Telugu                    87. Ukrainian                \n",
            " 88. Assamese                  89. Chuvash                   90. Silesian                 \n",
            " 91. Turkmen                   92. Romanian, Moldavian, ...  93. Persian                  \n",
            " 94. Tibetan Standard, Tib...  95. Latin                     96. Slovak                   \n",
            " 97. Sinhala, Sinhalese        98. Bavarian                  99. Icelandic                \n",
            "100. Mongolian                101. Walloon                  102. Portuguese               \n",
            "103. Urdu                     104. Gujarati                 105. Manx                     \n",
            "106. Tamil                    107. Khmer                    108. English                  \n",
            "109. Malay                    110. Chechen                  111. Bishnupriya Manipuri     \n",
            "112. Afrikaans                113. Basque                   114. Polish                   \n",
            "115. German                   116. Esperanto                117. Indonesian               \n",
            "118. Occitan                  119. Chinese                  120. Czech                    \n",
            "121. Hebrew (modern)          122. Romansh                  123. Lithuanian               \n",
            "124. Turkish                  125. Nepali                   126. Bosnian                  \n",
            "127. Interlingua              128. Zazaki                   129. Oriya                    \n",
            "130. Hungarian                131. Scottish Gaelic; Gaelic  132. Bashkir                  \n",
            "133. Thai                     134. Panjabi, Punjabi         135. Russian                  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from polyglot.text import Text, Word"
      ],
      "metadata": {
        "id": "CvkMBqj7-63W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! polyglot download morph2.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNia1hDQ-02c",
        "outputId": "3b0f9d87-f9b8-4327-9129-d4b1640e2cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[polyglot_data] Downloading package morph2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"preprocessing\", \"processor\", \"invaluable\", \"thankful\", \"crossed\"]\n",
        "for w in words:\n",
        "  w = Word(w, language=\"en\")\n",
        "  print(\"{:<20}{}\".format(w, w.morphemes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHW9qjw5CGZv",
        "outputId": "db78d339-7160-4809-999f-0383b3f66d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing       ['pre', 'process', 'ing']\n",
            "processor           ['process', 'or']\n",
            "invaluable          ['in', 'valuable']\n",
            "thankful            ['thank', 'ful']\n",
            "crossed             ['cross', 'ed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если с английским работает хорошо, совсем не значит, что с другими обещанными языками тоже."
      ],
      "metadata": {
        "id": "yZaII79xF__L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! polyglot download morph2.ru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J0TsjOgFiMS",
        "outputId": "bd620460-31d0-414f-a521-e17b8db0377d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[polyglot_data] Downloading package morph2.ru to\n",
            "[polyglot_data]     /root/polyglot_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"хождение\", \"предложение\", \"защищающихся\", \"привет\", \"вынуть\", \"поле\"]\n",
        "for w in words:\n",
        "  w = Word(w, language=\"ru\")\n",
        "  print(\"{:<20}{}\".format(w, w.morphemes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqnnifj2Fn0h",
        "outputId": "2e4b3443-83a6-42ae-d399-e807859ea3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "хождение            ['хождение']\n",
            "предложение         ['предложен', 'ие']\n",
            "защищающихся        ['защи', 'щ', 'а', 'ющихся']\n",
            "привет              ['при', 'вет']\n",
            "вынуть              ['вы', 'нуть']\n",
            "поле                ['поле']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С русским хорошо работает [XMorphy](https://github.com/alesapin/XMorphy)"
      ],
      "metadata": {
        "id": "bzJle58ZG8lq"
      }
    }
  ]
}