{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Вступление\n",
        "Мы уже видели морфологические анализаторы для русского языка (pymorphy, а ещё бывает Mystem, spacy и др.)\n",
        "\n"
      ],
      "metadata": {
        "id": "boS18Ma-gLDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wruIYdafVIJ",
        "outputId": "67ce9566-e202-4212-9e5b-a4645e1ef4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=fe425ae0431630e3d2de5ca93b58d0bbfd17e8af9848725811b8ce2d2625487d\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "metadata": {
        "id": "zD4ZKoyOiGBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('соня')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkqXodfLiKpk",
        "outputId": "634d9953-f7d0-4b88-aaa4-7c79503a28bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='соня', tag=OpencorporaTag('NOUN,anim,femn,Name sing,nomn'), normal_form='соня', score=0.666666, methods_stack=((DictionaryAnalyzer(), 'соня', 2917, 0),)),\n",
              " Parse(word='соня', tag=OpencorporaTag('NOUN,anim,ms-f sing,nomn'), normal_form='соня', score=0.333333, methods_stack=((DictionaryAnalyzer(), 'соня', 2918, 0),))]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "morph.parse('янос')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjdIPAPVkPiC",
        "outputId": "4dbdb783-364f-4648-b505-101cee288ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parse(word='янос', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='янос', score=0.3345588235294118, methods_stack=((DictionaryAnalyzer(), 'нос', 112, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'я'))),\n",
              " Parse(word='янос', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='янос', score=0.3345588235294118, methods_stack=((DictionaryAnalyzer(), 'нос', 112, 3), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'я'))),\n",
              " Parse(word='янос', tag=OpencorporaTag('NOUN,inan,masc sing,nomn'), normal_form='янос', score=0.1397058823529412, methods_stack=((FakeDictionary(), 'янос', 34, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'нос'))),\n",
              " Parse(word='янос', tag=OpencorporaTag('NOUN,inan,masc sing,accs'), normal_form='янос', score=0.1397058823529412, methods_stack=((FakeDictionary(), 'янос', 34, 3), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'нос'))),\n",
              " Parse(word='янос', tag=OpencorporaTag('ADJS,Qual masc,sing'), normal_form='яносый', score=0.04411764705882353, methods_stack=((FakeDictionary(), 'янос', 4, 27), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'нос'))),\n",
              " Parse(word='янос', tag=OpencorporaTag('ADVB'), normal_form='янос', score=0.00735294117647059, methods_stack=((FakeDictionary(), 'янос', 3, 0), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'нос')))]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Им дали много размеченных данных, они сделали обобщения\n",
        "\n",
        "[Pymorphy](https://pymorphy2.readthedocs.io/en/stable/) работает с русским и украинским\n",
        "\n",
        "[SpaCy](https://spacy.io/) работает c 25+ языками (это не только морфологические анализаторы, spacy - огромный проект, но об этом не сейчас)"
      ],
      "metadata": {
        "id": "d__HZXYViiZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# английский\n",
        "import spacy\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "text_en = (\"Colorless green ideas sleep furiously\")\n",
        "doc = nlp_en(text_en)\n",
        "for token in doc:\n",
        "   print([token.lemma_, token.pos_, token.morph])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIIc8Tx4k6I1",
        "outputId": "70f27a3f-4189-482d-a696-298d0339ec1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Colorless', 'PROPN', Number=Sing]\n",
            "['green', 'ADJ', Degree=Pos]\n",
            "['idea', 'NOUN', Number=Plur]\n",
            "['sleep', 'VERB', Tense=Pres|VerbForm=Fin]\n",
            "['furiously', 'ADV', ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZJBGt3WoobR",
        "outputId": "6e684f91-c612-4299-f29d-126c91722d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-07 03:14:58.702280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting fr-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.6.0/fr_core_news_sm-3.6.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (0.1.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->fr-core-news-sm==3.6.0) (2.1.3)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.6.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# французский\n",
        "nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
        "import fr_core_news_sm\n",
        "nlp_fr = fr_core_news_sm.load()\n",
        "doc = nlp_fr(\"C'est une phrase.\")\n",
        "for token in doc:\n",
        "   print([token.lemma_, token.pos_, token.morph])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b_0djUZoIMU",
        "outputId": "c0325e9c-0913-4672-b14d-6c675c9e60fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ce', 'PRON', Number=Sing|Person=3]\n",
            "['être', 'AUX', Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin]\n",
            "['un', 'DET', Definite=Ind|Gender=Fem|Number=Sing|PronType=Art]\n",
            "['phrase', 'NOUN', Gender=Fem|Number=Sing]\n",
            "['.', 'PUNCT', ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А ещё у spacy есть готовый pipeline* для тренировки вашего анализатора (возможно, платный доступ) на ваших размеченных данных\n",
        "\n",
        "*pipeline - цепочка действий(функций) для получения конечного результата\n",
        "\n",
        ">открыть холодильник -> достать бегемота -> положить пингвина -> закрыть холодильник\n",
        "\n",
        "Но снова нужно много размеченного материала."
      ],
      "metadata": {
        "id": "5kvmE4pYjEgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Если мало данных, можно использовать правила.\n",
        "\n",
        "Исходить из внешнего вида слова, думать о значении морфем."
      ],
      "metadata": {
        "id": "EX-TNtN5I0NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Отступление: какие бывают языки по тому, как устроено слово?\n",
        "\n",
        "- Аналитические\n",
        "- Синтетические\n",
        " - Флективные\n",
        " - Агглютинативные\n",
        "\n",
        "Для каких проще написать правила?"
      ],
      "metadata": {
        "id": "TbvXtMs7KusB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Английский пример (потому что знаем английский)\n",
        "\n",
        "Можно вручную расписывать, \"если s, а корень похож на существительное, то это существительное во множественном числе, а если корень похож на глагол, это 3е лицо ед.ч.\" И так условия для каждой морфемы. Но есть некоторые готовые способы записи правил."
      ],
      "metadata": {
        "id": "6O4E2BQeJoN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Трансдьюсеры\n",
        "Например [HFST](https://github.com/apertium/lexd/blob/main/Usage.md) (Helsinki Finite-State Transducer)"
      ],
      "metadata": {
        "id": "b2iSVU_Geqco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -sS https://apertium.projectjj.com/apt/install-release.sh | sudo bash\n",
        "!apt install apertium-all-dev lexd"
      ],
      "metadata": {
        "id": "QS7OQohkifQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4777fc69-4bee-4b68-f8eb-42c8a256e845"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning up old install, if any...\n",
            "removed '/etc/apt/trusted.gpg.d/apertium.gpg'\n",
            "removed '/etc/apt/preferences.d/apertium.pref'\n",
            "removed '/etc/apt/sources.list.d/apertium.list'\n",
            "Determining Debian/Ubuntu codename...\n",
            "Found evidence of jammy...\n",
            "Settling for jammy - enabling the Apertium release repo...\n",
            "Installing Apertium GnuPG key to /etc/apt/trusted.gpg.d/apertium.gpg\n",
            "Installing package override to /etc/apt/preferences.d/apertium.pref\n",
            "Creating /etc/apt/sources.list.d/apertium.list\n",
            "Running apt-get update...\n",
            "All done - enjoy the packages! If you just want all core tools, do: sudo apt-get install apertium-all-dev\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "apertium-all-dev is already the newest version (3.8.1-6~jammy1).\n",
            "lexd is already the newest version (1.3.1-2~jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это не питон, что это за язык? То, что после восклицательного знака - команды Linux (линуксовские), команды, которые работают в терминале"
      ],
      "metadata": {
        "id": "54BsbcD05V8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eng.lexd\n",
        "PATTERNS\n",
        "VerbRoot VerbInfl\n",
        "NounRoot NounInfl\n",
        "\n",
        "LEXICON VerbRoot\n",
        "sing\n",
        "walk\n",
        "dance\n",
        "\n",
        "LEXICON VerbInfl\n",
        "<v><pres>:\n",
        "<v><pres><p3><sg>:s\n",
        "\n",
        "LEXICON NounRoot\n",
        "cat\n",
        "dog\n",
        "\n",
        "LEXICON NounInfl\n",
        "<n><sg>:\n",
        "<n><pl>:s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM-I-FiB0Cej",
        "outputId": "2185c803-6dc0-458f-cf3d-ab643bfef279"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eng.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lexd eng.lexd > eng.generator.att\n",
        "!lt-comp rl eng.generator.att eng.analyser.bin\n",
        "! echo 'sings' | lt-proc eng.analyser.bin  # даёт разбор слова"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgOgZPnV0HZK",
        "outputId": "e799347b-dc65-4a47-b1ba-4f3883c4de2a"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 22 27\n",
            "^sings/sing<v><pres><p3><sg>$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo 'dogs' | lt-proc eng.analyser.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKxtxJUJIYhE",
        "outputId": "a4511b54-6c40-4e44-eea8-c05b2fe1d79d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^dogs/dog<n><pl>$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! lexd eng.lexd | hfst-txt2fst -o eng.generator.hfst\n",
        "! hfst-fst2strings eng.generator.hfst  # генерирует все возможные формы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSFZeQWN14uz",
        "outputId": "c3884b70-a7e2-48ae-c39f-eb41481ab3f7"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sing<v><pres>:sing\n",
            "sing<v><pres><p3><sg>:sings\n",
            "walk<v><pres>:walk\n",
            "walk<v><pres><p3><sg>:walks\n",
            "dance<v><pres>:dance\n",
            "dance<v><pres><p3><sg>:dances\n",
            "dog<n><sg>:dog\n",
            "dog<n><pl>:dogs\n",
            "cat<n><sg>:cat\n",
            "cat<n><pl>:cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если вы поняли логику, научитесь разбирать ещё слова cat, cats, dog, dogs."
      ],
      "metadata": {
        "id": "yZ2MKjqteDL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### А что происходит, что такое Finite-State Transducer?\n",
        "\n",
        "Finite-State Transducer - конечный преобразовывающий автомат\n",
        "\n",
        "Понятнее? :)\n",
        "\n",
        "Автомат - математическая модель, они бывают разные, поэтому давайте сразу про конечные автоматы\n",
        "\n",
        "\n",
        "Конечный атомат состоит из:\n",
        "- \"алфавита\" состояний\n",
        "- входного алфавита\n",
        "- переходов между состояниями\n",
        "- нального состояния\n",
        "- конечных состояний\n",
        "\n",
        "Можно представить в виде\n",
        "- графа\n",
        "- матрицы\n",
        "- БНФ (Бэкусовская нормальная форма или Бэкуса-Науэра форма)\n",
        "\n",
        "[картинка тут](https://github.com/tbkazakova/drafts/blob/main/auto.png)\n",
        "\n"
      ],
      "metadata": {
        "id": "lu5r7Gqlec1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бывают автоматы\n",
        "- распознающие — определяют соответствие входной цепочки конечному автомату\n",
        "- преобразующие — производят определенные действия по входной цепочке\n",
        "\n",
        "Наш автомат преобразующий: он ходит по слову и по частям заменяет слово на <морфологические теги>\n"
      ],
      "metadata": {
        "id": "IcevdkXAyvlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подвид КА (конечных автоматов):\n",
        "- стохастический КА — каждому переходу приписана его вероятность\n",
        "\n",
        "(в lexd можно это прописать, ведь есть более вероятные разборы и менее)"
      ],
      "metadata": {
        "id": "sIQQSGTN3rdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Возвращаемся к HFST\n",
        "На самом деле в HFST две больших части, два формализма [lexd](https://github.com/apertium/lexd/blob/main/Usage.md) и twolc (two-level compiler).\n",
        "\n",
        "twolc нужен для морфонологии. Порой одна глубинная форма реализуется по-разному. (примеры из русского?)\n",
        "\n",
        "Как это записать, если не хочется указывать в лексиконе алломорфы разными сущностями?\n",
        "\n",
        "Вот для этого и нужен twolc. two-level compiler: на первом уровне даём \"глубинные формы\", на втором расписываем их поверхностные реализации.\n"
      ],
      "metadata": {
        "id": "bz0Y8Zda4LTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eve.lexd\n",
        "PATTERNS\n",
        "VerbStem [<v>:] VerbTencePNum\n",
        "\n",
        "LEXICON VerbStem\n",
        "<уйти>:ur\n",
        "<прийти>:em\n",
        "\n",
        "PATTERN VerbTencePNum\n",
        "Verbpst VerbPNumpst\n",
        "\n",
        "LEXICON Verbpst\n",
        "<pst>:{R}i\n",
        "\n",
        "LEXICON VerbPNumpst\n",
        "<p1><sg>:wu\n",
        "<p1><sg>:w\n",
        "<p2><sg>:š\n",
        "<p3><sg>:n\n",
        "<p1><pl><inc>:t\n",
        "<p1><pl><exc>:wun\n",
        "<p2><pl>:šan\n",
        "<p3><pl>:tan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxWMQoolytwz",
        "outputId": "93fe4848-ea0d-4571-8c02-aac24281c88b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eve.lexd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lexd eve.lexd > eve.generator.att\n",
        "!lt-comp rl eve.generator.att eve.analyser.bin\n",
        "! echo 'urrin' | lt-proc eve.analyser.bin  # даёт разбор слова"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Asqnb3z2psl",
        "outputId": "3cade954-8dea-47cc-fe1b-7be768d33234"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main@standard 18 26\n",
            "^urrin/*urrin$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! lexd eve.lexd | hfst-txt2fst -o eve.generator.hfst\n",
        "! hfst-invert eve.generator.hfst -o eve.analyzer.hfst"
      ],
      "metadata": {
        "id": "X0ZK3pl11xdF"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eve.twol\n",
        "Alphabet\n",
        "  a b c d e f g i j k l m n o p r s t u v w x z ŋ č ž š ə ɨ ɵ γ\n",
        "  %{R%}:n %{R%}:r\n",
        ";\n",
        "Rules\n",
        "\"{R} m _ realisation\"\n",
        "%{R%}:n <=> m _ ;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUsfDPxr16ij",
        "outputId": "a6af7691-e44a-4f1f-a486-988c30787b8c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eve.twol\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! hfst-twolc eve.twol -o eve.twol.hfst\n",
        "! lexd eve.lexd | hfst-txt2fst -o eve.lexd.hfst\n",
        "#! hfst-fst2strings eve.lexd.hfst\n",
        "! hfst-compose-intersect eve.lexd.hfst eve.twol.hfst -o eve.generator.hfst\n",
        "#! hfst-fst2strings eve.generator.hfst\n",
        "! hfst-invert eve.generator.hfst -o eve.analyzer.hfst"
      ],
      "metadata": {
        "id": "i9TC1UVn1ag5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d4f8ad-e05d-4a16-cd3b-cda74f65b3ae"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading input from eve.twol.\n",
            "Writing output to eve.twol.hfst.\n",
            "Reading alphabet.\n",
            "Reading rules and compiling their contexts and centers.\n",
            "Compiling rules.\n",
            "Storing rules.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo \"urrin\" | hfst-lookup eve.analyzer.hfst"
      ],
      "metadata": {
        "id": "n8ya1Q0K0T5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd81874-1e29-42a8-ac5a-6a37a7f78e15"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hfst-lookup: warning: It is not possible to perform fast lookups with OpenFST, std arc, tropical semiring format automata.\n",
            "Using HFST basic transducer format and performing slow lookups\n",
            "> urrin\t<уйти><v><pst><p3><sg>\t0.000000\n",
            "\n",
            "> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ! echo \"emnin\" | hfst-lookup eve.analyzer.hfst\n",
        "a[2].split()[2]"
      ],
      "metadata": {
        "id": "YVWmb0rEQUx5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9f156c3f-4365-4f45-c26b-7d9c358399ff"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<прийти><v><pst><p3><sg>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ]
}